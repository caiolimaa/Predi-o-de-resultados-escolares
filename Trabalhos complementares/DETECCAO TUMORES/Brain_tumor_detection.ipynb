{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "geKhmTzjwjo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Brain tumor detection\n",
        "Predict the probability of tumor presence through MRI images of the brain."
      ],
      "metadata": {
        "id": "9R3u0t36l5i6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Before starting this notebook\n",
        "\n",
        "This notebook is designed for **experimental and learning ourposes**. <br/> It aims at solving the _target problem_ by evaluating (and documenting) _different solutions_ for somes steps of the **machine learning pipeline**. <br/> Due to its purposes, this notebook may contain notes, drafts, comments, etc.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "atznNH60p2cH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sprint Goals\n",
        "- Frame the problem\n",
        "- Get the data\n",
        "- Data cleaning\n",
        "- Simple EDA to gain insights\n",
        "- Initial data preprocessing\n",
        "- Train a (single) ML algorithm with all features and default hyperparameters\n",
        "---"
      ],
      "metadata": {
        "id": "BVc1ZkmBqL4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Frame the Problem"
      ],
      "metadata": {
        "id": "HPb3nuCkkJqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1 Context\n",
        "Tumors are swollen masses in the body caused by the abnormal growth of cells. When cancerous, the uncontrollable multiplication of cells has the potential to invade or spread to other parts of the body. <br/><br/> **Brain tumors** specifically are one of the deadliest cancers, and can have life long psychological impacts on the patient. <br/><br/> One of the diagnosis methods usually followed by hospitals is **MRI** (large machines with strong magnets connected to computers to take the detail picture of the brain. The professional responsible for the diagnosis, the radiologist, is, as any human, susceptible to inaccuraci in their work, which will affect the accuracy o detection. <br/><br/> In the attempt of reducing human errors and increasing the accuracy of detection of tumors, health experts have addopted modern technologies as to take advantage of its benefits and generate a scalable improvement in the area. The area of **Artificial Intelligence** have speacially led to exiting solutions with high accuracy at detecting the presence of tumors through MRI images.<br/><br/> This projects aims to implement a artificial intelligence at the task of detecting brain tumors as an attempt to assist and improve the accuracy of diagnosis."
      ],
      "metadata": {
        "id": "eqCodPE4kTei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Challenge \n",
        "Brain MRIs are images with lots of informations that are not pertinent to the detections and diagnosis of tumors.<br/>\n",
        "###Objective: \n",
        "**Build a machine learning solution to more accuratly predict the presence of tumors in MRI images.**<br/>\n",
        "###Baseline:\n",
        "Currently, there are some projects similar to this beeing slowly implemented in assisting health care professionals at diagnosing brain tumors. However, it is still a minority and this task is mostly done manually and is susceptive to human error.<br/>\n",
        "#### **Solution Planning:**\n",
        "- Neural network problem\n",
        "- Metrics:\n",
        "    - R²\n",
        "    - Root Mean Squared Error (RMSE)\n",
        "- Data sources:\n",
        "    - Brain Tumor Classification (MRI) [link text](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri?resource=download)\n",
        "- No assumptions\n",
        "- Project deliverable:\n",
        "    - A simple exploratory data analysis\n",
        "    - **A ML system/model** launched in _production_ <br/><br/> "
      ],
      "metadata": {
        "id": "ZEdBDBcqkYQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Get the Data"
      ],
      "metadata": {
        "id": "GZKrnKBHlDOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. Download the data\n",
        "We previously download the dataset from [kaggle](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri?resource=download).<br/>  The images are already split into Training and Testing folders.\n",
        "Each folder has more four subfolders. These folders have MRIs of respective tumor classes"
      ],
      "metadata": {
        "id": "wYlDJPi0lMMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. Importing dataset as a ZIP file"
      ],
      "metadata": {
        "id": "3igTo3KyQVc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '/content/archive.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "l4nhFT6kQVLY",
        "outputId": "72f090fc-4c7e-4dbb-9373-f485d261d68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4b854f384495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/archive.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3. Load Dependencies"
      ],
      "metadata": {
        "id": "2v5CYYSqOoSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nKr6VDBOPUM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4. Collect data"
      ],
      "metadata": {
        "id": "P8CrNh0GO6Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.listdir('/content/Training') #returns a list containing the names of the entries in the directory given by path\n",
        "classes = {'no_tumor':0, 'pituitary_tumor':1} #binary indicator of the presence of tumor\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for cls in classes:\n",
        "    pth = '/content/Training/'+cls\n",
        "    for j in os.listdir(pth):\n",
        "        img = cv2.imread(pth+'/'+j, 0) #loads an image from the specified file, the second space represents the flag, which specifies the way in which image should be read\n",
        "        img = cv2.resize(img, (200,200)) #changes the dimensions of the image\n",
        "        X.append(img)\n",
        "        Y.append(classes[cls])\n"
      ],
      "metadata": {
        "id": "RwGvEZI5PA-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "67f7a812-ca88-4fd5-ef2e-672349ae3d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-769826d6ae60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Training'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#returns a list containing the names of the entries in the directory given by path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'no_tumor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pituitary_tumor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#binary indicator of the presence of tumor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_updated = X.reshape(len(X), -1)"
      ],
      "metadata": {
        "id": "1BA5-3wxUjtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(Y)"
      ],
      "metadata": {
        "id": "bh-wUwPSUm4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(Y).value_counts() #returns a Series (one-dimensional ndarray with axis labels) containing counts of unique values in descending order so that the first element is the most frequently-occurring element (excludes NA values by default)"
      ],
      "metadata": {
        "id": "27KNEZDDU7od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X_updated.shape"
      ],
      "metadata": {
        "id": "Obe2UfOYVtw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6. Prepare data"
      ],
      "metadata": {
        "id": "giUZKVHvWKt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_updated = X.reshape(len(X), -1)\n",
        "X_updated.shape"
      ],
      "metadata": {
        "id": "5wwPSFRvWMNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.7. Split data"
      ],
      "metadata": {
        "id": "Qy5FIPJ0WSO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Splitting/samplig* the dataset into *training set* and *testing set*. The solution is trained using the *training set*, and the test is made using the *testing set*. <br/> The error rate - **generalization error** - is estimated through the test set. This value informs the predicted precision on instances it has never seen before."
      ],
      "metadata": {
        "id": "Rb6pS9c5zxJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(X_updated, Y, random_state=10, test_size=.20)"
      ],
      "metadata": {
        "id": "3SWC641LWTaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain.shape, xtest.shape"
      ],
      "metadata": {
        "id": "mrdlELQuWctU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Data Cleaning"
      ],
      "metadata": {
        "id": "Ro-e7F3w2dTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. Feature Scaling"
      ],
      "metadata": {
        "id": "CUgqjjUnWgMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to do scaling so that one significant number doesn’t impact the model just because of their large magnitude."
      ],
      "metadata": {
        "id": "fvK8WLlMgAc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.max(), xtrain.min())\n",
        "print(xtest.max(), xtest.min())\n",
        "xtrain = xtrain/255\n",
        "xtest = xtest/255\n",
        "print(xtrain.max(), xtrain.min())\n",
        "print(xtest.max(), xtest.min())"
      ],
      "metadata": {
        "id": "kL-_1HnKWikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. Feature Selection: PCA\n",
        "\n",
        "Proposed to select a subset of variables in principal component analysis (PCA) that preserves as much information present in the complete data as possible."
      ],
      "metadata": {
        "id": "4aVxgGPOWvcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.shape, xtest.shape)\n",
        "\n",
        "pca = PCA(.98)\n",
        "# pca_train = pca.fit_transform(xtrain)\n",
        "# pca_test = pca.transform(xtest)\n",
        "pca_train = xtrain\n",
        "pca_test = xtest"
      ],
      "metadata": {
        "id": "VbbjIpQrWu0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Explore the Data"
      ],
      "metadata": {
        "id": "GViUkv8R22Oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.1. Visualize data"
      ],
      "metadata": {
        "id": "LgQbugVyVzmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[0], cmap='gray') #display data as an image, i.e., on a 2D regular raster"
      ],
      "metadata": {
        "id": "kvndYR-2VyFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Train Model"
      ],
      "metadata": {
        "id": "yQUsHa7CHOpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Support-Vector Machine (SVM), is a supervised learning model with associated learning algorithms that analyze data for classification and regression analysis. An SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier. \n",
        "(Read more at: https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)"
      ],
      "metadata": {
        "id": "--jlEX_7Ir8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Logistic Regression Algorithm is a technique used for classification or prediction in data sets which have many features, but where most of them have little value and should be ignored. (Read more at: https://www.kdnuggets.com/2022/07/logistic-regression-work.html)"
      ],
      "metadata": {
        "id": "tOB7uGW8Jli7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Linear Support Vector Classifier (SVC) method applies a linear kernel function to perform classification and it performs well with a large number of samples. If we compare it with the SVC model, the Linear SVC has additional parameters such as penalty normalization which applies 'L1' or 'L2' and loss function.  (Read more at: https://www.datatechnotes.com/2020/07/classification-example-with-linearsvm-in-python.html)"
      ],
      "metadata": {
        "id": "fqhEy41P5B_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # warn the developer of situations that aren’t necessarily exceptions; not critical; it shows some message, but the program runs\n"
      ],
      "metadata": {
        "id": "oILwcp6zJZRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1. Models Test"
      ],
      "metadata": {
        "id": "GBgL014QUe9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an effort to determine the best, we created a function to calculate the model performance of the following models: Decision Tree Regressor, Random Forest Regressor, SVR, SVC and Logistic Regression."
      ],
      "metadata": {
        "id": "try2mFSqnsce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find the best model to use\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# create a function to calculate the model performance\n",
        "def model_performance(model, xtrain, xtest, ytrain, ytest):\n",
        "    model.fit(xtrain, ytrain)\n",
        "    ypred = model.predict(xtest)\n",
        "    rmse = np.sqrt(mean_squared_error(ytest, ypred))\n",
        "    mae = mean_absolute_error(ytest, ypred)\n",
        "    r2 = r2_score(ytest, ypred)\n",
        "    print(model)\n",
        "    print(f'RMSE: {rmse:.2f}') # Root Mean Squared Error\n",
        "    print(f'MAE: {mae:.2f}') # Mean absolute error\n",
        "    print(f'R2: {r2:.2f}') # Regression score; it is the difference between the samples in the dataset and the predictions made by the model\n",
        "\n",
        "#find the best model to use\n",
        "models = [DecisionTreeRegressor(), RandomForestRegressor(), SVR(), SVC(), LogisticRegression()]\n",
        "for model in models:\n",
        "    model_performance(model, xtrain, xtest, ytrain, ytest)\n",
        "    print('')"
      ],
      "metadata": {
        "id": "DevT59wdSvGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Metrics\n"
      ],
      "metadata": {
        "id": "0ZJXbdsUpJRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####R²\n",
        "The Regression Score (R²) is a summary measure that tells you how well the regression line fits the data. It is a value between 0 and 1 that represents proportion of total variability of the y-value that is accounted for by the independent variable x. It shows how well the model predicts the outcome.\n",
        "#####MSE\n",
        "Mean squared error regression loss. The loss is the mean overseen data of the squared differences between true and predicted values, or writing it as a formula. \n",
        "#####RMSE\n",
        "Is the square root of the MSE. Commonly used to compare regression models. It shows how far predictions fall from measured true values.\n",
        "#####MAE\n",
        "Computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss.\n"
      ],
      "metadata": {
        "id": "MmTxGFAp4FVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2. Trying a Neural Network model using tensorflow\n"
      ],
      "metadata": {
        "id": "2BZeYsyNyerg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.1. Importing dependencies"
      ],
      "metadata": {
        "id": "MU_TPANZ-yGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "v_el-Mk7yjtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.2. Rescaling images from the dataset"
      ],
      "metadata": {
        "id": "plXa62yd-2ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgd=ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "noWKeXn-ynym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.3. Exploring data"
      ],
      "metadata": {
        "id": "m9RWXHhy_CCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tumor_dataset=imgd.flow_from_directory('/content/Training')"
      ],
      "metadata": {
        "id": "T1ZIwNziysus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tumor_dataset.class_indices)\n",
        "classes=pd.DataFrame(tumor_dataset.classes)\n",
        "classes.value_counts()"
      ],
      "metadata": {
        "id": "GVKA9-XNy2C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.4. Splitting data"
      ],
      "metadata": {
        "id": "U7j8knUQ_Lrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = '/content/Training'\n",
        "path_test = '/content/Testing'\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "print(\"training\")\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "        path_train,\n",
        "        subset='training',\n",
        "        target_size=(200 , 200),\n",
        "        batch_size=32)\n",
        "print(\"validation\")\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "        path_train,\n",
        "        subset='validation',\n",
        "        target_size=(200 , 200),\n",
        "        batch_size=32 )\n",
        "print(\"testing\")\n",
        "test_data = train_datagen.flow_from_directory(\n",
        "        path_test,\n",
        "        target_size=(200 , 200),\n",
        "        batch_size=32 )"
      ],
      "metadata": {
        "id": "FTmKDswTzAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[1][1]"
      ],
      "metadata": {
        "id": "Pn5LiSo63wm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.5. Applying filter"
      ],
      "metadata": {
        "id": "LxJs5LOe_aS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten,Activation,Dense,Dropout,Conv2D,MaxPool2D"
      ],
      "metadata": {
        "id": "eG7XaqXyzhVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential()\n",
        "\n",
        "#convolution and maxpoollayer\n",
        "model.add(Conv2D(filters=25,kernel_size=3,\n",
        "                 strides=2,padding='valid',input_shape=(200,200,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=2))\n",
        "\n",
        "#flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#hidden layer\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fjxt208IzlMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SNUgHTe9zqrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.6. Training and validating data"
      ],
      "metadata": {
        "id": "IZ5aOaF3_1xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit (train_data,epochs=10, validation_data=val_data)"
      ],
      "metadata": {
        "id": "UYLi16-FzsIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.7. Analysing results"
      ],
      "metadata": {
        "id": "_mjqfyjz_-wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Vs Epochs of CNN')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy');"
      ],
      "metadata": {
        "id": "WB_zybRV1auW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_data)"
      ],
      "metadata": {
        "id": "WhzeSlTL1c5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "2DicXU7f1eOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicte=model.predict(test_data)\n",
        "y_predicte"
      ],
      "metadata": {
        "id": "kjIiDlWu1mCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The displayed results show close proximity in values of prediction, and can indicate a tendency to inaccuracy. This, however, will have to be more closely analyzed with tools such as a confusion matrix."
      ],
      "metadata": {
        "id": "S86e73L0q7RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.8. Testing model"
      ],
      "metadata": {
        "id": "2YRuOW-cAd1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.listdir('/content/Testing') #returns a list containing the names of the entries in the directory given by path\n",
        "classes = {'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3} # indicator of the presence of tumor\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for cls in classes:\n",
        "    pth = '/content/Testing/'+cls\n",
        "    for j in os.listdir(pth):\n",
        "        img = cv2.imread(pth+'/'+j, 0) #loads an image from the specified file, the second space represents the flag, which specifies the way in which image should be read\n",
        "        img = cv2.resize(img, (200,200)) #changes the dimensions of the image\n",
        "        X.append(img)\n",
        "        Y.append(classes[cls])"
      ],
      "metadata": {
        "id": "dL7QJoA3BAk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tumor_classes=['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\n",
        "for i in range (len(y_predicte)):\n",
        "    predicted_tumor=tumor_classes[np.argmax(y_predicte[i])]\n",
        "    print(predicted_tumor)"
      ],
      "metadata": {
        "id": "0WO6euok1oZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model can predict and give results, but a visual display has yet to be implemented."
      ],
      "metadata": {
        "id": "NVoyGSshrjk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Evaluation"
      ],
      "metadata": {
        "id": "SliZ6XbhLkTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data from the metrics used to avaluate the training shows that, amongst the models tested (Decision Tree Regressor, Random Forest Regressor, SVR, SVC and Logistic Regression), the one that provides the most accurate results for this project is the Random Forest Regressor model.<br/> The Random Forest Regressor showed an accuracy of 97%, therefore, we decided to go ahead with testings using this model."
      ],
      "metadata": {
        "id": "R7FBBD8N8RoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "fAXVwNEA9stL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observe, Random Forest Regressor showed a great balance among training an testing score. So we can reach to the conclusion that it is ideal model for this particular dataset."
      ],
      "metadata": {
        "id": "Q60kTWikMAac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Prediction"
      ],
      "metadata": {
        "id": "gG3CxFH2MG6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = reg.predict(xtest)"
      ],
      "metadata": {
        "id": "d9obZ0hCMJWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = np.where(ytest!=pred)\n",
        "misclassified"
      ],
      "metadata": {
        "id": "oKljmmbpMc_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Misclassified Samples: \",len(misclassified[0]))\n",
        "print(pred[36],ytest[36])"
      ],
      "metadata": {
        "id": "peikO07PMd5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Testing"
      ],
      "metadata": {
        "id": "DJ4hlVdaMfp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dec = {0:'No Tumor', 1:'Positive Tumor'}"
      ],
      "metadata": {
        "id": "clYBqfCeNM_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "p = os.listdir('/content/Testing/')\n",
        "c=1\n",
        "for i in os.listdir('/content/Testing/no_tumor/')[:9]:\n",
        "    plt.subplot(3,3,c)\n",
        "    \n",
        "    img = cv2.imread('/content/Testing/no_tumor/'+i,0)\n",
        "    img1 = cv2.resize(img, (200,200))\n",
        "    img1 = img1.reshape(1,-1)/255\n",
        "    p = reg.predict(img1)\n",
        "    assert(0.0 <= p[0] <= 1.0)\n",
        "    idx = 0 if p[0] < 0.5 else 1\n",
        "    #print(dec[p[0]]) ##\n",
        "    plt.title(dec[idx])\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    c+=1"
      ],
      "metadata": {
        "id": "3tZjVzsxNRJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "p = os.listdir('/content/Testing/')\n",
        "c=1\n",
        "for i in os.listdir('/content/Testing/pituitary_tumor/')[:16]:\n",
        "    plt.subplot(4,4,c)\n",
        "    \n",
        "    img = cv2.imread('/content/Testing/pituitary_tumor/'+i,0)\n",
        "    img1 = cv2.resize(img, (200,200))\n",
        "    img1 = img1.reshape(1,-1)/255\n",
        "    p = reg.predict(img1)\n",
        "    assert(0.0 <= p[0] <= 1.0)\n",
        "    idx = 0 if p[0] < 0.5 else 1\n",
        "    plt.title(dec[idx])\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    c+=1"
      ],
      "metadata": {
        "id": "KZsETw73NXVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A visual indicator of the location of the tumor has yet to be implemented."
      ],
      "metadata": {
        "id": "06NctPJprzLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. Conclusion"
      ],
      "metadata": {
        "id": "bgHNWpVHnQd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.1. Used models"
      ],
      "metadata": {
        "id": "Ok9RTqaWou5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After implementing the displayed models, we have reached satisfactory tumor prediction results - with an accuracy of 97% in training. However, we were unable to fully implement the desired model, which was Neural Network, and we have yet to better analyze the results said model provided (comparing the accuracy of the different types of tumors and implementing a confusion matrix as to visualize this data)."
      ],
      "metadata": {
        "id": "cF6RI4Qkna4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.2. Next steps"
      ],
      "metadata": {
        "id": "kjZe7RFapeo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving forward, we intend to attempt again to implement and analyze a Neural Network model. Moreover, we plan on applying a visual indicator of the detection of the tumors when displaying prediction results. Such improvements will hopefully create a better and more accurate assistance to medical professionals on providing a tumor diagnosis."
      ],
      "metadata": {
        "id": "i44m8hW5qxU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.3. Acknowledgments"
      ],
      "metadata": {
        "id": "UFnqCNz-r5wW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said previously, this notebook is intended only for research and learning purposes. We thank our professor and the online community for providing the tools and explanations we needed to complete this project."
      ],
      "metadata": {
        "id": "gw0YVUk4sC9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.4. References"
      ],
      "metadata": {
        "id": "zUoGcVorsf3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Kummar, Ajitesh. \"SVM Classifier using Sklearn: Code Examples\". Data Analytics, May 6, 2022. URL:https://vitalflux.com/svm-classifier-scikit-learn-code-examples/. <br/>\n",
        "\"Metrics and scoring: quantifying the quality of predictions\". scikit learn. URL: https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix. <br/>\n",
        "machine-learning. github, Oct 26, 2019. URL: https://github.com/laurelkeys/machine-learning/blob/master/assignment-2/Assignment2.ipynb.<br/>\n",
        "Jadhav, Kishor. \"brain tumor classification with 99% train accuracy\".kaggle, Aug 8, 2022. URL: https://www.kaggle.com/code/kishorjadhav1/brain-tumor-classification-with-99-train-accuracy/data.<br/>\n",
        "\"Root Mean Square Error (RMSE)\". C3.ai. URL: https://c3.ai/glossary/data-science/root-mean-square-error-rmse/.<br/>\n",
        "\"Mean squared error\". Knowledge Center. URL: https://peltarion.com/knowledge-center/modeling-view/build-an-ai-model/loss-functions/mean-squared-error. <br/>\n",
        "Abhishek Anil, Aditya Raj, H Aravind Sarma, Naveen Chandran R, Deepa P L. \"Brain Tumor detection from brain MRI using Deep Learning\". International Journal of Innovative Research in Applied Sciences and Engineering (IJIRASE)\n",
        "Volume 3, Issue 2, DOI: 10.29027/IJIRASE.v3.i2.2019, 458-465, August 2019. URL:https://ijirase.com/assets/paper/issue_1/volume_3/V3-Issue-2-458-465.pdf. <br/>\n",
        "\"Brain Tumor Classification MRI | Brain Tumor Detection using Support Vector Machine in Python\". Coding With Aman Dhillon, May 19, 2021. URL: https://www.youtube.com/watch?v=5lgrlddp-98. <br/>\n",
        "\"brain tumor detection using python and sklearn\". github, jul 11, 2021. URL: https://github.com/akd6203/brain-tumor-detection.<br/>\n",
        "\"Brain_tumor_classifier_97%+_accuracy\". kaggle, Jun 9, 2022. URL: https://www.kaggle.com/code/die9origephit/brain-tumor-classifier-97-accuracy."
      ],
      "metadata": {
        "id": "oRm2Dno0slc4"
      }
    }
  ]
}